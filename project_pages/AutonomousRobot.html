<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About Me</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <div class="header">
        <h1 id="title">ZACHARY HAHN</h1>
        <div class="navbar">
            <div class="navbar_menu">
                <a href=../index.html>Home</a>
                <div class="dropdown">
                    <button class="dropbtn">Projects</button>
                    <div class="dropdown-content">
                        <a href=../project_pages/AutonomousRobot.html>Autonomous Robot</a>
                        <a href=../project_pages/AnimatronicWolf.html >Animatronic Wolf</a>
                        <a href=../project_pages/ScootCase.html>ScootCase</a>
                        <a href=../project_pages/Check.html>Check</a>
                        <a href=../project_pages/Sprout.html>Sprout</a>
                        <a href=../project_pages/MEMS.html>MEMS Microphone</a>
                        <a href=../project_pages/InjectionMold.html>Injection Mold</a>
                        <a href=../project_pages/StirlingEngine.html>Stirling Engine</a>
                        <a href=../project_pages/PennAir.html>Penn Aerial Robotics</a>
                        <a href=../project_pages/CarbonFiber.html>Carbon Fiber Layup</a>
                        <a href=../project_pages/SurfaceModel.html>Surface Model</a>
                        <a href=../project_pages/DeskCandy.html>Desk Candy</a>
                    </div>
                </div>
                <a href=../about_me.html>About Me</a>
                <a href=../resume.html>Resume</a>
                <a href="mailto:zwhahn@gmail.com">Contact</a>
            </div>
        </div>
    </div>
    <div class="main">
        <h1>Autonomous Robot</h1>
        <div class="content">
            <div class="grid">
                <img height=300 src="../images/AutonomousRobot/Robot_square.jpg">
                <div class="span2">
                    <p class="span2">This project was created as part of the systems engineering course Controls for Autonomous Vehicles. 
                    The goal was to create a robot that could autonomously navigate a path using computer vision, IR sensors, and IMUs.</p>
                    <p class="span2">A car platform was provided with all necessary hardware including a Romi 32U4 control board, IR sensors, 
                    camera, and an LED display, but no software libraries were provided. Overall, I gained experience with control 
                    theory (Simulink, PID's, filtering, pure pursuit, dead reckoning, etc.) while also building on my software skills 
                    (Arduino, MATLAB). </p>
                </div>
                
                <h2 class="subsection span3">Wall Following</h2>
                <p class="span3">The first challenge tackled in this course was getting the robot to follow a wall at a constant distant. PID control was 
                    used to achieve zero steady state error while the IR sensors were used to measure wall distance. </p>
                <iframe class="span3" width="560" height="315" src="https://www.youtube.com/embed/IFBHnihmxKc?si=rKdy7j0KSL4WcKy1" 
                title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <p class="span3">I built a complete, closed loop Simulink model to simulate the robot's motion. I experimented with different types of feedback and 
                    the resulting plots are shown below.</p>
                <figure>
                    <img src="../images/AutonomousRobot/ProportionFeedback_unstable.png">
                    <figcaption>Proportional Feedback <br> (Unstable)</figcaption>
                </figure>

                <figure>
                    <img src="../images/AutonomousRobot/ProportionalDerivative.png">
                    <figcaption>Proportional + Derivative Feedback <br> (Stready-State Error)</figcaption>
                </figure>

                <figure>
                    <img src="../images/AutonomousRobot/PDI.png">
                    <figcaption>Proportional + Derivative + Integral Feedback <br><br> </figcaption>
                </figure>
                
                <h2 class="subsection span3">Pure Pursuit and Bezier Curves</h2>
                <div class="span2">
                    <p>Next,  pure pursuit with Bezier curves was considered. Bezier curves have two major benefits for robotic path planning. First, they have few turning points and are 
                        therefore more smooth. Second, the tangent vectors of the curve at the first and last control point are directed along the Bezier polygon. This allows easy control 
                        of the robots final location and orientation.
                    </p>
                    <p>To the right is a Matlab script that allows the user to select n number of waypoints (which act as the first and last control point) for the robot to travel to. 
                        Once the waypoints have been chosen, two control points are calculated between the waypoints (green dots). Then, Bezier curves are drawn for each set of four 
                        control points (red line). Finally, the path of the path of the robot is calculated using a Simulink model and overlaid (blue line).
                    </p>
                </div>   
                <img src="../images/AutonomousRobot/PurePursuit.gif">

                <h2 class="subsection span3">Dead Reckoning and Kalman Filter</h2>
                <video class="span3" controls="controls" name="Dead Reckoning">
                    <source src="../images/AutonomousRobot/DeadReckoningPath.mov">
                </video>
                <div class="span3">
                    <p>Dead reckoning was implemented using wheel encoders to calculate both distance traveled and steering angle. The robot executes straight-line motion between successive
                        waypoint. The velocity is preset by the user, while the change in steering is executed by feedback on the orientation error. Once the robot reaches the final waypoint,
                        it revisits the waypoints in reverse order.</p>
                    <p>Dead reckoning is subject to cumulative error. For this reason a Kalman filter is used as a correction method. Using the encoders we know the position of the robot with 
                        some accuracy. The orange cones (seen in the video above) act as fiducial markers. The robot knows where the cones are supposed to be in space and the IR sensor is able 
                        to read the robots actual location from them, again with some accuracy. The Kalman filter is able to combine these two data points to create a more accurate guess to 
                        where the robot is. Finally, a correction step is implemented so the robot will remain on the correct path over time.   </p>
                </div>

                <h2 class="subsection span3">Computer Vision</h2>
                <div class="span3 two_images">
                    <img src="../images/AutonomousRobot/Cone.png">
                    <img src="../images/AutonomousRobot/ConeOutline.png">
                </div>
                <p class="span3">To replace the IR sensors, computer vision was used to identify and locate cones. The pinhole camera model was used to determine location. </p>
                <p class="span3">I wrote my computer vision scrip in MATLAB. First, I converted all images to HSV. Next, I translated the image to black and white using a custom HSV threshold. 
                    Then, I was able to use edge detection and identify the largest zone. Finally, the left-most point on the zone is identified as the corner and the pixel values of the center 
                    of the cone can be found using simple algebra. </p>
                <p class="span3">Now, the pixel location of the cone, the height of the camera off the ground, and the focal length are all known. The global coordinates of the cone can be 
                    calculated using the pinhole camera model.</p>
                <p class="span3">Unfortunately, due to course time constraints the computer vision was not integrated into the vehicle controls.</p>
                
            </div>
            <!-- <img src="../images/AutonomousRobot/Robot_square.jpg" alt="Autonomous Robot"> -->
        </div>
    </div>
</body>
</html>